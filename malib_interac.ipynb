{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from malib.train import train\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "class SpiralDataset(Dataset):\n",
    "    def __init__(self, N, K):\n",
    "        self.X, self.y = self.generate_spiral_dataset(N, K)\n",
    "        \n",
    "        # Convert numpy arrays to PyTorch tensors\n",
    "        self.X = torch.from_numpy(self.X).float()\n",
    "        self.y = torch.from_numpy(self.y).long()\n",
    "\n",
    "    def generate_spiral_dataset(self, N, K):\n",
    "        X = np.zeros((N*K, 2)) # data matrix (each row = single example)\n",
    "        y = np.zeros(N*K, dtype='uint8') # class labels\n",
    "\n",
    "        for j in range(K):\n",
    "            ix = range(N*j, N*(j+1))\n",
    "            r = np.linspace(0.0, 1, N) # rayon\n",
    "            t = np.linspace(j*4, (j+1)*4, N) + np.random.randn(N)*0.2 # theta\n",
    "            X[ix] = np.c_[r*np.sin(t), r*np.cos(t)]\n",
    "            y[ix] = j\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "N = 100 # number of points per class\n",
    "K = 3 # number of classes\n",
    "\n",
    "spiral_dataset_train = SpiralDataset(N, K)\n",
    "spiral_dataset_test = SpiralDataset(N, K)\n",
    "\n",
    "train_loader = DataLoader(spiral_dataset_train, batch_size=3*N, shuffle=True)\n",
    "test_loader = DataLoader(spiral_dataset_train, batch_size=3*N, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(2, 10)\n",
    "        self.fc2 = nn.Linear(10, 10)\n",
    "        self.fc3 = nn.Linear(10, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/500. Loss=0.776606023311615\n",
      "Epoch 1/500. Loss=0.7697689533233643\n",
      "Epoch 2/500. Loss=0.7627350091934204\n",
      "Epoch 3/500. Loss=0.7559328675270081\n",
      "Epoch 4/500. Loss=0.7493581771850586\n",
      "Epoch 5/500. Loss=0.7428911924362183\n",
      "Epoch 6/500. Loss=0.7364201545715332\n",
      "Epoch 7/500. Loss=0.7299900650978088\n",
      "Epoch 8/500. Loss=0.7236257195472717\n",
      "Epoch 9/500. Loss=0.7173200845718384\n",
      "Epoch 10/500. Loss=0.7109372615814209\n",
      "Epoch 11/500. Loss=0.7042123675346375\n",
      "Epoch 12/500. Loss=0.6971761584281921\n",
      "Epoch 13/500. Loss=0.6898736357688904\n",
      "Epoch 14/500. Loss=0.6825350522994995\n",
      "Epoch 15/500. Loss=0.675251305103302\n",
      "Epoch 16/500. Loss=0.6681879162788391\n",
      "Epoch 17/500. Loss=0.6615259051322937\n",
      "Epoch 18/500. Loss=0.6550375819206238\n",
      "Epoch 19/500. Loss=0.6485284566879272\n",
      "Epoch 20/500. Loss=0.6419057250022888\n",
      "Epoch 21/500. Loss=0.6351152062416077\n",
      "Epoch 22/500. Loss=0.6281653642654419\n",
      "Epoch 23/500. Loss=0.6211393475532532\n",
      "Epoch 24/500. Loss=0.6140297055244446\n",
      "Epoch 25/500. Loss=0.6069065928459167\n",
      "Epoch 26/500. Loss=0.5999192595481873\n",
      "Epoch 27/500. Loss=0.5929137468338013\n",
      "Epoch 28/500. Loss=0.5859516263008118\n",
      "Epoch 29/500. Loss=0.5789980292320251\n",
      "Epoch 30/500. Loss=0.5720784664154053\n",
      "Epoch 31/500. Loss=0.5651701092720032\n",
      "Epoch 32/500. Loss=0.5582353472709656\n",
      "Epoch 33/500. Loss=0.5511871576309204\n",
      "Epoch 34/500. Loss=0.5440816283226013\n",
      "Epoch 35/500. Loss=0.5370165109634399\n",
      "Epoch 36/500. Loss=0.5299899578094482\n",
      "Epoch 37/500. Loss=0.5229105353355408\n",
      "Epoch 38/500. Loss=0.5157890915870667\n",
      "Epoch 39/500. Loss=0.5088014006614685\n",
      "Epoch 40/500. Loss=0.501862108707428\n",
      "Epoch 41/500. Loss=0.4949968457221985\n",
      "Epoch 42/500. Loss=0.4880964756011963\n",
      "Epoch 43/500. Loss=0.48125067353248596\n",
      "Epoch 44/500. Loss=0.47444525361061096\n",
      "Epoch 45/500. Loss=0.46769168972969055\n",
      "Epoch 46/500. Loss=0.46103209257125854\n",
      "Epoch 47/500. Loss=0.45452263951301575\n",
      "Epoch 48/500. Loss=0.4481757581233978\n",
      "Epoch 49/500. Loss=0.441916823387146\n",
      "Epoch 50/500. Loss=0.4357389211654663\n",
      "Epoch 51/500. Loss=0.4295279383659363\n",
      "Epoch 52/500. Loss=0.4233536422252655\n",
      "Epoch 53/500. Loss=0.41747692227363586\n",
      "Epoch 54/500. Loss=0.41172870993614197\n",
      "Epoch 55/500. Loss=0.4060908555984497\n",
      "Epoch 56/500. Loss=0.40056899189949036\n",
      "Epoch 57/500. Loss=0.3950977027416229\n",
      "Epoch 58/500. Loss=0.3896450996398926\n",
      "Epoch 59/500. Loss=0.3843320608139038\n",
      "Epoch 60/500. Loss=0.37903493642807007\n",
      "Epoch 61/500. Loss=0.37379661202430725\n",
      "Epoch 62/500. Loss=0.3686385750770569\n",
      "Epoch 63/500. Loss=0.36350175738334656\n",
      "Epoch 64/500. Loss=0.35843175649642944\n",
      "Epoch 65/500. Loss=0.35336992144584656\n",
      "Epoch 66/500. Loss=0.3482729196548462\n",
      "Epoch 67/500. Loss=0.34333279728889465\n",
      "Epoch 68/500. Loss=0.3384402096271515\n",
      "Epoch 69/500. Loss=0.3335763216018677\n",
      "Epoch 70/500. Loss=0.32873502373695374\n",
      "Epoch 71/500. Loss=0.32397109270095825\n",
      "Epoch 72/500. Loss=0.3192000687122345\n",
      "Epoch 73/500. Loss=0.31452009081840515\n",
      "Epoch 74/500. Loss=0.30981603264808655\n",
      "Epoch 75/500. Loss=0.30512505769729614\n",
      "Epoch 76/500. Loss=0.3004172146320343\n",
      "Epoch 77/500. Loss=0.2956416606903076\n",
      "Epoch 78/500. Loss=0.2909822165966034\n",
      "Epoch 79/500. Loss=0.28630831837654114\n",
      "Epoch 80/500. Loss=0.28174012899398804\n",
      "Epoch 81/500. Loss=0.27721863985061646\n",
      "Epoch 82/500. Loss=0.27273792028427124\n",
      "Epoch 83/500. Loss=0.2682684063911438\n",
      "Epoch 84/500. Loss=0.26372039318084717\n",
      "Epoch 85/500. Loss=0.2592722475528717\n",
      "Epoch 86/500. Loss=0.25470805168151855\n",
      "Epoch 87/500. Loss=0.25026360154151917\n",
      "Epoch 88/500. Loss=0.24585680663585663\n",
      "Epoch 89/500. Loss=0.2414499670267105\n",
      "Epoch 90/500. Loss=0.2371271699666977\n",
      "Epoch 91/500. Loss=0.2328505963087082\n",
      "Epoch 92/500. Loss=0.22864866256713867\n",
      "Epoch 93/500. Loss=0.22448387742042542\n",
      "Epoch 94/500. Loss=0.22032219171524048\n",
      "Epoch 95/500. Loss=0.21629132330417633\n",
      "Epoch 96/500. Loss=0.21238023042678833\n",
      "Epoch 97/500. Loss=0.20848293602466583\n",
      "Epoch 98/500. Loss=0.20467571914196014\n",
      "Epoch 99/500. Loss=0.20098930597305298\n",
      "Epoch 100/500. Loss=0.19734670221805573\n",
      "Epoch 101/500. Loss=0.1936766654253006\n",
      "Epoch 102/500. Loss=0.1901252269744873\n",
      "Epoch 103/500. Loss=0.1867491751909256\n",
      "Epoch 104/500. Loss=0.18349912762641907\n",
      "Epoch 105/500. Loss=0.18035359680652618\n",
      "Epoch 106/500. Loss=0.17734560370445251\n",
      "Epoch 107/500. Loss=0.17447373270988464\n",
      "Epoch 108/500. Loss=0.1716948002576828\n",
      "Epoch 109/500. Loss=0.16900882124900818\n",
      "Epoch 110/500. Loss=0.16636914014816284\n",
      "Epoch 111/500. Loss=0.16378003358840942\n",
      "Epoch 112/500. Loss=0.16123685240745544\n",
      "Epoch 113/500. Loss=0.1586409956216812\n",
      "Epoch 114/500. Loss=0.1559312641620636\n",
      "Epoch 115/500. Loss=0.15303127467632294\n",
      "Epoch 116/500. Loss=0.15009571611881256\n",
      "Epoch 117/500. Loss=0.14723408222198486\n",
      "Epoch 118/500. Loss=0.14431098103523254\n",
      "Epoch 119/500. Loss=0.14139927923679352\n",
      "Epoch 120/500. Loss=0.13853593170642853\n",
      "Epoch 121/500. Loss=0.13574357330799103\n",
      "Epoch 122/500. Loss=0.13300074636936188\n",
      "Epoch 123/500. Loss=0.13034534454345703\n",
      "Epoch 124/500. Loss=0.12777931988239288\n",
      "Epoch 125/500. Loss=0.12526719272136688\n",
      "Epoch 126/500. Loss=0.12285817414522171\n",
      "Epoch 127/500. Loss=0.12050499022006989\n",
      "Epoch 128/500. Loss=0.11826691776514053\n",
      "Epoch 129/500. Loss=0.11612838506698608\n",
      "Epoch 130/500. Loss=0.11402511596679688\n",
      "Epoch 131/500. Loss=0.1119605153799057\n",
      "Epoch 132/500. Loss=0.10997983068227768\n",
      "Epoch 133/500. Loss=0.1080545037984848\n",
      "Epoch 134/500. Loss=0.10620453208684921\n",
      "Epoch 135/500. Loss=0.10440386086702347\n",
      "Epoch 136/500. Loss=0.10268402844667435\n",
      "Epoch 137/500. Loss=0.10104285180568695\n",
      "Epoch 138/500. Loss=0.09937508404254913\n",
      "Epoch 139/500. Loss=0.09773314744234085\n",
      "Epoch 140/500. Loss=0.09613166749477386\n",
      "Epoch 141/500. Loss=0.0945647656917572\n",
      "Epoch 142/500. Loss=0.0930289551615715\n",
      "Epoch 143/500. Loss=0.0915326327085495\n",
      "Epoch 144/500. Loss=0.09007254242897034\n",
      "Epoch 145/500. Loss=0.08865059912204742\n",
      "Epoch 146/500. Loss=0.08726480603218079\n",
      "Epoch 147/500. Loss=0.08595442026853561\n",
      "Epoch 148/500. Loss=0.08470695465803146\n",
      "Epoch 149/500. Loss=0.08347675949335098\n",
      "Epoch 150/500. Loss=0.08225109428167343\n",
      "Epoch 151/500. Loss=0.08105204254388809\n",
      "Epoch 152/500. Loss=0.07988372445106506\n",
      "Epoch 153/500. Loss=0.07876703143119812\n",
      "Epoch 154/500. Loss=0.07768075913190842\n",
      "Epoch 155/500. Loss=0.07661464810371399\n",
      "Epoch 156/500. Loss=0.07557044178247452\n",
      "Epoch 157/500. Loss=0.07455368340015411\n",
      "Epoch 158/500. Loss=0.0735655128955841\n",
      "Epoch 159/500. Loss=0.07259706407785416\n",
      "Epoch 160/500. Loss=0.07164766639471054\n",
      "Epoch 161/500. Loss=0.07073642313480377\n",
      "Epoch 162/500. Loss=0.06985191255807877\n",
      "Epoch 163/500. Loss=0.06899385154247284\n",
      "Epoch 164/500. Loss=0.06815067678689957\n",
      "Epoch 165/500. Loss=0.06732721626758575\n",
      "Epoch 166/500. Loss=0.06653819233179092\n",
      "Epoch 167/500. Loss=0.06576933711767197\n",
      "Epoch 168/500. Loss=0.0650254562497139\n",
      "Epoch 169/500. Loss=0.06430131942033768\n",
      "Epoch 170/500. Loss=0.06359145045280457\n",
      "Epoch 171/500. Loss=0.06289726495742798\n",
      "Epoch 172/500. Loss=0.06222248077392578\n",
      "Epoch 173/500. Loss=0.061560261994600296\n",
      "Epoch 174/500. Loss=0.06091593578457832\n",
      "Epoch 175/500. Loss=0.06029370799660683\n",
      "Epoch 176/500. Loss=0.05968189239501953\n",
      "Epoch 177/500. Loss=0.059080466628074646\n",
      "Epoch 178/500. Loss=0.058502133935689926\n",
      "Epoch 179/500. Loss=0.05793392285704613\n",
      "Epoch 180/500. Loss=0.05737980455160141\n",
      "Epoch 181/500. Loss=0.056839752942323685\n",
      "Epoch 182/500. Loss=0.056311722844839096\n",
      "Epoch 183/500. Loss=0.055802032351493835\n",
      "Epoch 184/500. Loss=0.055301863700151443\n",
      "Epoch 185/500. Loss=0.0548103004693985\n",
      "Epoch 186/500. Loss=0.05432739108800888\n",
      "Epoch 187/500. Loss=0.05386054515838623\n",
      "Epoch 188/500. Loss=0.05340602248907089\n",
      "Epoch 189/500. Loss=0.0529627725481987\n",
      "Epoch 190/500. Loss=0.05252824351191521\n",
      "Epoch 191/500. Loss=0.05210074037313461\n",
      "Epoch 192/500. Loss=0.05167945846915245\n",
      "Epoch 193/500. Loss=0.05126800015568733\n",
      "Epoch 194/500. Loss=0.05086720362305641\n",
      "Epoch 195/500. Loss=0.05047674849629402\n",
      "Epoch 196/500. Loss=0.05009445548057556\n",
      "Epoch 197/500. Loss=0.049720555543899536\n",
      "Epoch 198/500. Loss=0.04935012012720108\n",
      "Epoch 199/500. Loss=0.048982080072164536\n",
      "Epoch 200/500. Loss=0.04862004891037941\n",
      "Epoch 201/500. Loss=0.048263683915138245\n",
      "Epoch 202/500. Loss=0.04791358485817909\n",
      "Epoch 203/500. Loss=0.04756839945912361\n",
      "Epoch 204/500. Loss=0.047228340059518814\n",
      "Epoch 205/500. Loss=0.046895015984773636\n",
      "Epoch 206/500. Loss=0.046569108963012695\n",
      "Epoch 207/500. Loss=0.04624740406870842\n",
      "Epoch 208/500. Loss=0.04592883586883545\n",
      "Epoch 209/500. Loss=0.04561590775847435\n",
      "Epoch 210/500. Loss=0.04530896246433258\n",
      "Epoch 211/500. Loss=0.04500891640782356\n",
      "Epoch 212/500. Loss=0.044713094830513\n",
      "Epoch 213/500. Loss=0.04442310333251953\n",
      "Epoch 214/500. Loss=0.044134583324193954\n",
      "Epoch 215/500. Loss=0.04385219141840935\n",
      "Epoch 216/500. Loss=0.04357369244098663\n",
      "Epoch 217/500. Loss=0.043300461024045944\n",
      "Epoch 218/500. Loss=0.04303181171417236\n",
      "Epoch 219/500. Loss=0.042768318206071854\n",
      "Epoch 220/500. Loss=0.04250936582684517\n",
      "Epoch 221/500. Loss=0.04225413501262665\n",
      "Epoch 222/500. Loss=0.04200281947851181\n",
      "Epoch 223/500. Loss=0.041755080223083496\n",
      "Epoch 224/500. Loss=0.041511327028274536\n",
      "Epoch 225/500. Loss=0.04127086326479912\n",
      "Epoch 226/500. Loss=0.04103343188762665\n",
      "Epoch 227/500. Loss=0.040801115334033966\n",
      "Epoch 228/500. Loss=0.040571440011262894\n",
      "Epoch 229/500. Loss=0.040344785898923874\n",
      "Epoch 230/500. Loss=0.040122080594301224\n",
      "Epoch 231/500. Loss=0.03990336135029793\n",
      "Epoch 232/500. Loss=0.039688367396593094\n",
      "Epoch 233/500. Loss=0.039475563913583755\n",
      "Epoch 234/500. Loss=0.03926569223403931\n",
      "Epoch 235/500. Loss=0.039057519286870956\n",
      "Epoch 236/500. Loss=0.03885085880756378\n",
      "Epoch 237/500. Loss=0.03864753246307373\n",
      "Epoch 238/500. Loss=0.038449499756097794\n",
      "Epoch 239/500. Loss=0.03825578838586807\n",
      "Epoch 240/500. Loss=0.03806499391794205\n",
      "Epoch 241/500. Loss=0.03787529468536377\n",
      "Epoch 242/500. Loss=0.037688396871089935\n",
      "Epoch 243/500. Loss=0.03750332444906235\n",
      "Epoch 244/500. Loss=0.03732046112418175\n",
      "Epoch 245/500. Loss=0.03714154288172722\n",
      "Epoch 246/500. Loss=0.03696560487151146\n",
      "Epoch 247/500. Loss=0.036789681762456894\n",
      "Epoch 248/500. Loss=0.03661585971713066\n",
      "Epoch 249/500. Loss=0.036443762481212616\n",
      "Epoch 250/500. Loss=0.03627464175224304\n",
      "Epoch 251/500. Loss=0.03610770404338837\n",
      "Epoch 252/500. Loss=0.035942912101745605\n",
      "Epoch 253/500. Loss=0.035780832171440125\n",
      "Epoch 254/500. Loss=0.03561961650848389\n",
      "Epoch 255/500. Loss=0.035461585968732834\n",
      "Epoch 256/500. Loss=0.035305656492710114\n",
      "Epoch 257/500. Loss=0.03515119105577469\n",
      "Epoch 258/500. Loss=0.03499846160411835\n",
      "Epoch 259/500. Loss=0.034847620874643326\n",
      "Epoch 260/500. Loss=0.034698303788900375\n",
      "Epoch 261/500. Loss=0.03455064445734024\n",
      "Epoch 262/500. Loss=0.03440488502383232\n",
      "Epoch 263/500. Loss=0.034260936081409454\n",
      "Epoch 264/500. Loss=0.03411932289600372\n",
      "Epoch 265/500. Loss=0.03397933021187782\n",
      "Epoch 266/500. Loss=0.03384067490696907\n",
      "Epoch 267/500. Loss=0.033703673630952835\n",
      "Epoch 268/500. Loss=0.03356855362653732\n",
      "Epoch 269/500. Loss=0.03343556821346283\n",
      "Epoch 270/500. Loss=0.033303797245025635\n",
      "Epoch 271/500. Loss=0.0331735759973526\n",
      "Epoch 272/500. Loss=0.033044975250959396\n",
      "Epoch 273/500. Loss=0.03291710093617439\n",
      "Epoch 274/500. Loss=0.03279006481170654\n",
      "Epoch 275/500. Loss=0.03266437351703644\n",
      "Epoch 276/500. Loss=0.032541465014219284\n",
      "Epoch 277/500. Loss=0.032420627772808075\n",
      "Epoch 278/500. Loss=0.03229941800236702\n",
      "Epoch 279/500. Loss=0.03217855095863342\n",
      "Epoch 280/500. Loss=0.032060541212558746\n",
      "Epoch 281/500. Loss=0.031944163143634796\n",
      "Epoch 282/500. Loss=0.03182898834347725\n",
      "Epoch 283/500. Loss=0.03171461448073387\n",
      "Epoch 284/500. Loss=0.03160076215863228\n",
      "Epoch 285/500. Loss=0.031487658619880676\n",
      "Epoch 286/500. Loss=0.03137535974383354\n",
      "Epoch 287/500. Loss=0.031265683472156525\n",
      "Epoch 288/500. Loss=0.031157249584794044\n",
      "Epoch 289/500. Loss=0.031049203127622604\n",
      "Epoch 290/500. Loss=0.030942494049668312\n",
      "Epoch 291/500. Loss=0.030836690217256546\n",
      "Epoch 292/500. Loss=0.030732082203030586\n",
      "Epoch 293/500. Loss=0.030629608780145645\n",
      "Epoch 294/500. Loss=0.030527185648679733\n",
      "Epoch 295/500. Loss=0.030425166711211205\n",
      "Epoch 296/500. Loss=0.030324408784508705\n",
      "Epoch 297/500. Loss=0.030223922803997993\n",
      "Epoch 298/500. Loss=0.030124085023999214\n",
      "Epoch 299/500. Loss=0.0300250593572855\n",
      "Epoch 300/500. Loss=0.02992687188088894\n",
      "Epoch 301/500. Loss=0.029829489067196846\n",
      "Epoch 302/500. Loss=0.029732925817370415\n",
      "Epoch 303/500. Loss=0.029637156054377556\n",
      "Epoch 304/500. Loss=0.029541173949837685\n",
      "Epoch 305/500. Loss=0.029445165768265724\n",
      "Epoch 306/500. Loss=0.02934974618256092\n",
      "Epoch 307/500. Loss=0.029254935681819916\n",
      "Epoch 308/500. Loss=0.02916116639971733\n",
      "Epoch 309/500. Loss=0.02906692586839199\n",
      "Epoch 310/500. Loss=0.028973976150155067\n",
      "Epoch 311/500. Loss=0.028881333768367767\n",
      "Epoch 312/500. Loss=0.02878991700708866\n",
      "Epoch 313/500. Loss=0.028700226917862892\n",
      "Epoch 314/500. Loss=0.02861025743186474\n",
      "Epoch 315/500. Loss=0.028520463034510612\n",
      "Epoch 316/500. Loss=0.028431778773665428\n",
      "Epoch 317/500. Loss=0.028344258666038513\n",
      "Epoch 318/500. Loss=0.02825743705034256\n",
      "Epoch 319/500. Loss=0.028171241283416748\n",
      "Epoch 320/500. Loss=0.028085744008421898\n",
      "Epoch 321/500. Loss=0.028000619262456894\n",
      "Epoch 322/500. Loss=0.027916112914681435\n",
      "Epoch 323/500. Loss=0.02783289924263954\n",
      "Epoch 324/500. Loss=0.027750186622142792\n",
      "Epoch 325/500. Loss=0.02766793966293335\n",
      "Epoch 326/500. Loss=0.027586014941334724\n",
      "Epoch 327/500. Loss=0.02750435285270214\n",
      "Epoch 328/500. Loss=0.027423318475484848\n",
      "Epoch 329/500. Loss=0.027343181893229485\n",
      "Epoch 330/500. Loss=0.027262836694717407\n",
      "Epoch 331/500. Loss=0.027182407677173615\n",
      "Epoch 332/500. Loss=0.02710244245827198\n",
      "Epoch 333/500. Loss=0.027022186666727066\n",
      "Epoch 334/500. Loss=0.02694232389330864\n",
      "Epoch 335/500. Loss=0.026862945407629013\n",
      "Epoch 336/500. Loss=0.02678413689136505\n",
      "Epoch 337/500. Loss=0.02670648880302906\n",
      "Epoch 338/500. Loss=0.026629434898495674\n",
      "Epoch 339/500. Loss=0.02655305154621601\n",
      "Epoch 340/500. Loss=0.02647721953690052\n",
      "Epoch 341/500. Loss=0.02640211209654808\n",
      "Epoch 342/500. Loss=0.026327647268772125\n",
      "Epoch 343/500. Loss=0.026253707706928253\n",
      "Epoch 344/500. Loss=0.026180289685726166\n",
      "Epoch 345/500. Loss=0.02610750123858452\n",
      "Epoch 346/500. Loss=0.026035241782665253\n",
      "Epoch 347/500. Loss=0.025963420048356056\n",
      "Epoch 348/500. Loss=0.025891730561852455\n",
      "Epoch 349/500. Loss=0.02582005225121975\n",
      "Epoch 350/500. Loss=0.025749269872903824\n",
      "Epoch 351/500. Loss=0.025679294019937515\n",
      "Epoch 352/500. Loss=0.02560998685657978\n",
      "Epoch 353/500. Loss=0.025541158393025398\n",
      "Epoch 354/500. Loss=0.025472979992628098\n",
      "Epoch 355/500. Loss=0.025405248627066612\n",
      "Epoch 356/500. Loss=0.025338193401694298\n",
      "Epoch 357/500. Loss=0.025271669030189514\n",
      "Epoch 358/500. Loss=0.025205541402101517\n",
      "Epoch 359/500. Loss=0.02513985149562359\n",
      "Epoch 360/500. Loss=0.025074629113078117\n",
      "Epoch 361/500. Loss=0.025009911507368088\n",
      "Epoch 362/500. Loss=0.024945776909589767\n",
      "Epoch 363/500. Loss=0.02488200180232525\n",
      "Epoch 364/500. Loss=0.02481866627931595\n",
      "Epoch 365/500. Loss=0.02475581131875515\n",
      "Epoch 366/500. Loss=0.02469351887702942\n",
      "Epoch 367/500. Loss=0.024631891399621964\n",
      "Epoch 368/500. Loss=0.02457074075937271\n",
      "Epoch 369/500. Loss=0.024510061368346214\n",
      "Epoch 370/500. Loss=0.024450069293379784\n",
      "Epoch 371/500. Loss=0.02439061738550663\n",
      "Epoch 372/500. Loss=0.02433127351105213\n",
      "Epoch 373/500. Loss=0.02427230216562748\n",
      "Epoch 374/500. Loss=0.024213707074522972\n",
      "Epoch 375/500. Loss=0.024155253544449806\n",
      "Epoch 376/500. Loss=0.024097034707665443\n",
      "Epoch 377/500. Loss=0.024039071053266525\n",
      "Epoch 378/500. Loss=0.02398112788796425\n",
      "Epoch 379/500. Loss=0.02392318844795227\n",
      "Epoch 380/500. Loss=0.023865921422839165\n",
      "Epoch 381/500. Loss=0.023808656260371208\n",
      "Epoch 382/500. Loss=0.023751839995384216\n",
      "Epoch 383/500. Loss=0.023695645853877068\n",
      "Epoch 384/500. Loss=0.023639613762497902\n",
      "Epoch 385/500. Loss=0.023584328591823578\n",
      "Epoch 386/500. Loss=0.023528723046183586\n",
      "Epoch 387/500. Loss=0.023474233224987984\n",
      "Epoch 388/500. Loss=0.0234193317592144\n",
      "Epoch 389/500. Loss=0.0233653225004673\n",
      "Epoch 390/500. Loss=0.023311713710427284\n",
      "Epoch 391/500. Loss=0.0232583899050951\n",
      "Epoch 392/500. Loss=0.02320544794201851\n",
      "Epoch 393/500. Loss=0.02315286174416542\n",
      "Epoch 394/500. Loss=0.0231005921959877\n",
      "Epoch 395/500. Loss=0.02304885722696781\n",
      "Epoch 396/500. Loss=0.022997451946139336\n",
      "Epoch 397/500. Loss=0.02294638566672802\n",
      "Epoch 398/500. Loss=0.022895699366927147\n",
      "Epoch 399/500. Loss=0.022845491766929626\n",
      "Epoch 400/500. Loss=0.022795412689447403\n",
      "Epoch 401/500. Loss=0.022745462134480476\n",
      "Epoch 402/500. Loss=0.022697141394019127\n",
      "Epoch 403/500. Loss=0.022647447884082794\n",
      "Epoch 404/500. Loss=0.02259952761232853\n",
      "Epoch 405/500. Loss=0.02255099080502987\n",
      "Epoch 406/500. Loss=0.022503551095724106\n",
      "Epoch 407/500. Loss=0.022455815225839615\n",
      "Epoch 408/500. Loss=0.02240840345621109\n",
      "Epoch 409/500. Loss=0.022361522540450096\n",
      "Epoch 410/500. Loss=0.0223142821341753\n",
      "Epoch 411/500. Loss=0.022268183529376984\n",
      "Epoch 412/500. Loss=0.022222133353352547\n",
      "Epoch 413/500. Loss=0.02217605523765087\n",
      "Epoch 414/500. Loss=0.022130504250526428\n",
      "Epoch 415/500. Loss=0.022085200995206833\n",
      "Epoch 416/500. Loss=0.02204039879143238\n",
      "Epoch 417/500. Loss=0.021995574235916138\n",
      "Epoch 418/500. Loss=0.021951215341687202\n",
      "Epoch 419/500. Loss=0.021907003596425056\n",
      "Epoch 420/500. Loss=0.02186257392168045\n",
      "Epoch 421/500. Loss=0.02181876264512539\n",
      "Epoch 422/500. Loss=0.02177511900663376\n",
      "Epoch 423/500. Loss=0.021731633692979813\n",
      "Epoch 424/500. Loss=0.021688641980290413\n",
      "Epoch 425/500. Loss=0.021645722910761833\n",
      "Epoch 426/500. Loss=0.021602846682071686\n",
      "Epoch 427/500. Loss=0.02155992016196251\n",
      "Epoch 428/500. Loss=0.021517472341656685\n",
      "Epoch 429/500. Loss=0.02147521637380123\n",
      "Epoch 430/500. Loss=0.02143319509923458\n",
      "Epoch 431/500. Loss=0.0213916078209877\n",
      "Epoch 432/500. Loss=0.02135017327964306\n",
      "Epoch 433/500. Loss=0.021308980882167816\n",
      "Epoch 434/500. Loss=0.021268343552947044\n",
      "Epoch 435/500. Loss=0.021227871999144554\n",
      "Epoch 436/500. Loss=0.021187452599406242\n",
      "Epoch 437/500. Loss=0.021147223189473152\n",
      "Epoch 438/500. Loss=0.021107451990246773\n",
      "Epoch 439/500. Loss=0.021067827939987183\n",
      "Epoch 440/500. Loss=0.02102847211062908\n",
      "Epoch 441/500. Loss=0.020989369601011276\n",
      "Epoch 442/500. Loss=0.020950520411133766\n",
      "Epoch 443/500. Loss=0.020911937579512596\n",
      "Epoch 444/500. Loss=0.020873507484793663\n",
      "Epoch 445/500. Loss=0.020835453644394875\n",
      "Epoch 446/500. Loss=0.02079756185412407\n",
      "Epoch 447/500. Loss=0.020759791135787964\n",
      "Epoch 448/500. Loss=0.020722413435578346\n",
      "Epoch 449/500. Loss=0.020685190334916115\n",
      "Epoch 450/500. Loss=0.02064833603799343\n",
      "Epoch 451/500. Loss=0.020611582323908806\n",
      "Epoch 452/500. Loss=0.020575061440467834\n",
      "Epoch 453/500. Loss=0.02053884044289589\n",
      "Epoch 454/500. Loss=0.02050279639661312\n",
      "Epoch 455/500. Loss=0.020466912537813187\n",
      "Epoch 456/500. Loss=0.020431388169527054\n",
      "Epoch 457/500. Loss=0.02039598859846592\n",
      "Epoch 458/500. Loss=0.02036074921488762\n",
      "Epoch 459/500. Loss=0.02032581903040409\n",
      "Epoch 460/500. Loss=0.020291149616241455\n",
      "Epoch 461/500. Loss=0.020256653428077698\n",
      "Epoch 462/500. Loss=0.020222226157784462\n",
      "Epoch 463/500. Loss=0.020187951624393463\n",
      "Epoch 464/500. Loss=0.020153872668743134\n",
      "Epoch 465/500. Loss=0.020119937136769295\n",
      "Epoch 466/500. Loss=0.020086245611310005\n",
      "Epoch 467/500. Loss=0.02005275897681713\n",
      "Epoch 468/500. Loss=0.020019475370645523\n",
      "Epoch 469/500. Loss=0.01998741552233696\n",
      "Epoch 470/500. Loss=0.019954072311520576\n",
      "Epoch 471/500. Loss=0.019921790808439255\n",
      "Epoch 472/500. Loss=0.01988980360329151\n",
      "Epoch 473/500. Loss=0.01985774002969265\n",
      "Epoch 474/500. Loss=0.019826075062155724\n",
      "Epoch 475/500. Loss=0.019794166088104248\n",
      "Epoch 476/500. Loss=0.019762521609663963\n",
      "Epoch 477/500. Loss=0.019730782136321068\n",
      "Epoch 478/500. Loss=0.019699156284332275\n",
      "Epoch 479/500. Loss=0.019667718559503555\n",
      "Epoch 480/500. Loss=0.0196364838629961\n",
      "Epoch 481/500. Loss=0.019605379551649094\n",
      "Epoch 482/500. Loss=0.019574416801333427\n",
      "Epoch 483/500. Loss=0.01954367756843567\n",
      "Epoch 484/500. Loss=0.019513046368956566\n",
      "Epoch 485/500. Loss=0.019482651725411415\n",
      "Epoch 486/500. Loss=0.019452359527349472\n",
      "Epoch 487/500. Loss=0.01942238211631775\n",
      "Epoch 488/500. Loss=0.019392700865864754\n",
      "Epoch 489/500. Loss=0.019363263621926308\n",
      "Epoch 490/500. Loss=0.01933395490050316\n",
      "Epoch 491/500. Loss=0.019304679706692696\n",
      "Epoch 492/500. Loss=0.019275551661849022\n",
      "Epoch 493/500. Loss=0.01924649067223072\n",
      "Epoch 494/500. Loss=0.019217507913708687\n",
      "Epoch 495/500. Loss=0.019188618287444115\n",
      "Epoch 496/500. Loss=0.01915988139808178\n",
      "Epoch 497/500. Loss=0.01913129724562168\n",
      "Epoch 498/500. Loss=0.019102798774838448\n",
      "Epoch 499/500. Loss=0.01907445304095745\n"
     ]
    }
   ],
   "source": [
    "train(model, train_loader, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
